import cv2
import json
import numpy as np
import time
import tqdm
from tqdm import tqdm
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed

def get_hit_frame(json_path):
    with open(json_path, 'r') as f:
        data = json.load(f)
    for frame_info in data:
        if frame_info.get("tennis_ball_hit", False):
            return frame_info["frame"]
    return None

def get_video_info(video_path):
    cap = cv2.VideoCapture(video_path)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    duration = total_frames / fps
    cap.release()
    return total_frames, fps, duration
"""
def process_video(input_path, output_path, start_frame, frames_to_process, dimensions):
    cap = cv2.VideoCapture(input_path)
    width, height = dimensions
    
    # ğŸŸ¢ ç„¡è«–æ˜¯å¦æ”¯æ´ CUDAï¼Œéƒ½å…ˆå®šç¾© fourccï¼Œé¿å…è®Šæ•¸ä¸å­˜åœ¨
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')

    # è‹¥å¯ç”¨ CUDAï¼Œå‰‡å¯åœ¨æœªä¾†åŠ é€Ÿè§£ç¢¼ï¼ˆå¯é¸ï¼‰
    if cv2.cuda.getCudaEnabledDeviceCount() > 0:
        print("[INFO] CUDA device detected, using GPU-accelerated video processing.")
    else:
        print("[INFO] No CUDA device detected, using CPU mode.")

    # åˆå§‹åŒ–è¼¸å‡º
    out = cv2.VideoWriter(output_path, fourcc, cap.get(cv2.CAP_PROP_FPS), (width, height))
    
    # è¨­ç½®è®€å–ç·©è¡å€å¤§å°
    cap.set(cv2.CAP_PROP_BUFFERSIZE, 1024)
    
    # è·³åˆ°èµ·å§‹å¹€
    cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)
    
    batch_size = 32
    frames = []
    
    for i in range(0, frames_to_process, batch_size):
        batch_frames = min(batch_size, frames_to_process - i)
        for _ in range(batch_frames):
            ret, frame = cap.read()
            if not ret:
                break
            frames.append(frame)
        
        for frame in frames:
            out.write(frame)
        frames = []

    cap.release()
    out.release()

"""
def process_video(input_path, output_path, start_frame, frames_to_process, dimensions):
    cap = cv2.VideoCapture(input_path)
    width, height = dimensions
    
    # ä½¿ç”¨ H.264 ç·¨ç¢¼å™¨æå‡æ•ˆèƒ½
    if cv2.cuda.getCudaEnabledDeviceCount() > 0:
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    
    out = cv2.VideoWriter(output_path, fourcc, cap.get(cv2.CAP_PROP_FPS), (width, height))
    
    # è¨­ç½®è®€å–ç·©è¡å€å¤§å°
    cap.set(cv2.CAP_PROP_BUFFERSIZE, 1024)
    
    # ç›´æ¥è·³åˆ°èµ·å§‹å¹€
    cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)
    
    # æ‰¹æ¬¡è®€å–å’Œå¯«å…¥
    batch_size = 32
    frames = []
    
    for i in range(0, frames_to_process, batch_size):
        batch_frames = min(batch_size, frames_to_process - i)
        for _ in range(batch_frames):
            ret, frame = cap.read()
            if not ret:
                break
            frames.append(frame)
        
        # æ‰¹æ¬¡å¯«å…¥
        for frame in frames:
            out.write(frame)
        frames = []
    
    cap.release()
    out.release()

def synchronize_videos(input_path_1, input_path_2, json_path_1, json_path_2):
    trim_length=60

    # ç²å–å½±ç‰‡è³‡è¨Š
    frames1, fps1, duration1 = get_video_info(input_path_1)
    frames2, fps2, duration2 = get_video_info(input_path_2)
    
    print("\nåŸå§‹å½±ç‰‡è³‡è¨Š:")
    print(f"å½±ç‰‡ 1: {frames1} å¹€, {duration1:.2f} ç§’")
    print(f"å½±ç‰‡ 2: {frames2} å¹€, {duration2:.2f} ç§’")

    # ç²å–æ“Šçƒå¹€
    hit_frame_1 = get_hit_frame(json_path_1)
    hit_frame_2 = get_hit_frame(json_path_2)
    
    print(f"\næ“Šçƒå¹€ä½ç½®:")
    print(f"å½±ç‰‡ 1: ç¬¬ {hit_frame_1} å¹€")
    print(f"å½±ç‰‡ 2: ç¬¬ {hit_frame_2} å¹€")

    # è¨ˆç®—å‰ªè¼¯ç¯„åœ
    max_frames_after = min(frames1 - hit_frame_1, frames2 - hit_frame_2)
    max_frames_before = min(hit_frame_1, hit_frame_2)
    
    frames_before = min(trim_length // 2, max_frames_before)
    frames_after = min(trim_length - frames_before, max_frames_after)
    
    start_frame_1 = hit_frame_1 - frames_before
    start_frame_2 = hit_frame_2 - frames_before
    frames_to_process = frames_before + frames_after

    print(f"\nå‰ªè¼¯è³‡è¨Š:")
    print(f"å½±ç‰‡ 1: å¾ç¬¬ {start_frame_1} å¹€åˆ°ç¬¬ {start_frame_1 + frames_to_process} å¹€")
    print(f"å½±ç‰‡ 2: å¾ç¬¬ {start_frame_2} å¹€åˆ°ç¬¬ {start_frame_2 + frames_to_process} å¹€")

    # ç²å–å½±ç‰‡å°ºå¯¸
    cap1 = cv2.VideoCapture(input_path_1)
    cap2 = cv2.VideoCapture(input_path_2)
    dimensions1 = (int(cap1.get(cv2.CAP_PROP_FRAME_WIDTH)), 
                  int(cap1.get(cv2.CAP_PROP_FRAME_HEIGHT)))
    dimensions2 = (int(cap2.get(cv2.CAP_PROP_FRAME_WIDTH)), 
                  int(cap2.get(cv2.CAP_PROP_FRAME_HEIGHT)))
    cap1.release()
    cap2.release()

    output_path_1 = input_path_1
    output_path_2 = input_path_2

    # ä½¿ç”¨ç·šç¨‹æ± ä¸¦è¡Œè™•ç†å…©å€‹å½±ç‰‡
    with ThreadPoolExecutor(max_workers=2) as executor:
        futures = [
            executor.submit(process_video, input_path_1, output_path_1, 
                          start_frame_1, frames_to_process, dimensions1),
            executor.submit(process_video, input_path_2, output_path_2, 
                          start_frame_2, frames_to_process, dimensions2)
        ]
        
        # ç­‰å¾…æ‰€æœ‰è™•ç†å®Œæˆ
        for future in as_completed(futures):
            try:
                future.result()
            except Exception as e:
                print(f"è™•ç†éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {str(e)}")

    final_duration = frames_to_process / fps1
    print(f"\næœ€çµ‚å½±ç‰‡è³‡è¨Š:")
    print(f"å…©å€‹å½±ç‰‡éƒ½æ˜¯ {frames_to_process} å¹€, {final_duration:.2f} ç§’")
    print("\nåŒæ­¥å®Œæˆ!")

if __name__ == "__main__":
    start_time = time.time()
    
    input_video_1 = "pro_1_1_45_temp.mp4"
    input_video_2 = "pro_1_1_side_temp.mp4"
    json_path_1 = "pro_1_1_45_temp(2D_trajectory_smoothed).json"
    json_path_2 = "pro_1_1_side_temp(2D_trajectory_smoothed).json"

    print("é–‹å§‹åŸ·è¡Œå½±ç‰‡åŒæ­¥...")
    synchronize_videos(input_video_1, input_video_2, json_path_1, json_path_2)
    
    print(f"åŸ·è¡Œæ™‚é–“: {time.time() - start_time:.4f}ç§’")